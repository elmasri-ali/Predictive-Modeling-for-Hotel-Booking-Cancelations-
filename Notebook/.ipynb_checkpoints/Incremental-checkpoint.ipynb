{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babed345-5c2c-4ed1-a412-1463f23ee8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the preprocessor\n",
    "with open('preprocessor.pkl', 'rb') as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "\n",
    "# Load the model\n",
    "model = NeuralNetwork(input_dim, hidden_layer_sizes, dropout).to(device)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Load the incremental data\n",
    "with open('incremental_data.pkl', 'rb') as f:\n",
    "    X_incremental, y_incremental = pickle.load(f)\n",
    "\n",
    "# Transform the incremental data using the preprocessor\n",
    "X_incremental_preprocessed = preprocessor.transform(X_incremental)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_incremental_tensor = torch.tensor(X_incremental_preprocessed, dtype=torch.float32)\n",
    "y_incremental_tensor = torch.tensor(y_incremental.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "incremental_dataset = TensorDataset(X_incremental_tensor, y_incremental_tensor)\n",
    "incremental_loader = DataLoader(incremental_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd1dac-bc6b-4b26-a186-9a989b7a37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_train(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "def validate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.round()\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return running_loss / len(data_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18133ddc-5def-45ad-bafa-e9fe83b2bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = BCELoss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Define early stopping parameters\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Load the validation data\n",
    "with open('validation_data.pkl', 'rb') as f:\n",
    "    X_val, y_val = pickle.load(f)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Incremental training with early stopping\n",
    "num_epochs = 10  # Set the number of epochs for incremental training\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = incremental_train(model, incremental_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# Save the updated model (optional)\n",
    "torch.save(model.state_dict(), 'updated_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322fbf5-3fb6-435a-80c7-1376e9be90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "with open('test_data.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def test(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.round()\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return running_loss / len(data_loader), accuracy\n",
    "\n",
    "# Test the updated model\n",
    "test_loss, test_accuracy = test(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f9c3c-124c-4ab0-b6f2-95dfc98d43e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb87c5-acac-4d85-93de-37e82b6aaa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb93231-de0d-4a39-b3e2-5c6fe9b2627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e258054-9b72-445d-8aa0-65075d7aefd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5075f-db70-4b81-ad7f-0fd09a54a23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385979c-3e35-4bc3-ac02-b97904eeac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12685b-fcc3-45fe-bf91-8fbc24709647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d6619-f8d7-4b8c-8846-59bbf52ae41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
